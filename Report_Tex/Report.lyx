#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble


\usepackage[english]{babel}
\usepackage[style=numeric, backend=biber]{biblatex}
\usepackage{csquotes}
\addbibresource{bibliography.bib}
%opening
\title{RoboCup Final Project Report \\ Color Detection }
\author{Jakob Stimpfl \and Charlotte Burmeister}
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding utf8
\fontencoding T1
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_package amsmath 1
\use_package amssymb 0
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
maketitle
\end_layout

\end_inset

 
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
The Nao robot is a humanoid robot produced by Aldebaran.
 It is 574 mm high and has xx joints, controlled by stepper motors.+
\end_layout

\begin_layout Standard
In this project to goal was to enable the robot to listen to a color, interpret
 the color heard as RGB values, search for that color in a set distance
 in front of him and then point to this color.
\end_layout

\begin_layout Section
Implementation
\end_layout

\begin_layout Standard
As predetermined by the course the Python Software Development Kit (SDK)
 was used.
 This SDK provides the use of C++ modules and enables the user to create
 own Python modules.
\begin_inset CommandInset citation
LatexCommand cite
key "API"

\end_inset


\end_layout

\begin_layout Subsection
Speech Detection
\end_layout

\begin_layout Standard
The first part of the project aims at implementing a speech recognition
 and distinguish the different colors.
 Therefore the module "ALSpeechRecognition" was used.
 It provides the event listener "WordRecognized".
 When subscribed to this module, an event is thrown when a word is recognized
 from the vocabulary list which is specified beforehand.
 Once the event is detected and thrown, the program jumps to the method
 "OnColorHeard", there a simple if-query determines the color.
 Afterwards the next method is called with tho colors Red-Green-Blue values
 which is described in the following section.
 
\end_layout

\begin_layout Subsection
Color Detection
\end_layout

\begin_layout Standard
Since the API provides a module 
\begin_inset Quotes eld
\end_inset

ALColorBlobDetection
\begin_inset Quotes erd
\end_inset

 for finding a color-blob we could use that one.
 To find the color we want to search for, we have to set its RGB-Values
 and a threshold with the methode 
\begin_inset Quotes eld
\end_inset

setColor(r, g, b, th)
\begin_inset Quotes erd
\end_inset

.
 By try and error we found out, that a threshold of 50 seems to produce
 good results.
 Additionaly we set the minimal size of our blob to 10 pixels and its distance
 depending the distance we want to search for in: 
\begin_inset Quotes eld
\end_inset

setObjectProperties(10, distance)
\begin_inset Quotes erd
\end_inset

.
 Then we subscribe for the 
\begin_inset Quotes eld
\end_inset

onColorDetected
\begin_inset Quotes erd
\end_inset

-event.
 If that event is thrown in the eventhandler we use the 
\begin_inset Quotes eld
\end_inset

getCircle()
\begin_inset Quotes erd
\end_inset

-methode to determine the to the width of our picture relative x-value.
 
\end_layout

\begin_layout Subsection
Movement
\end_layout

\begin_layout Standard
As described in the previuos section at this point we have an x-value which
 we can use to calculate the angle we have to moove our arm in, to point
 at our object.
 As a first distinction we determine whether this x-value is greater than
 0.5.
 In that case we use the right arm otherwise the left.
 Since the calculation for the left arm is the same then for the right with
 the small difference, that the pointing-angle has to be negated, we will
 subsequently explain the calculations only for the right arm.
 
\end_layout

\begin_layout Standard
Since we have the normalized x-value counted from the left side of the picture
 we have to calculate the distance from the robots center by multiplying
 it with the horizon-lenght which in by our definition is the size an object
 could maximal have, in the set distance, so that the robot could still
 see all of it.
 For that we need annother parameter, by name, the opening angle of our
 camera, defined in the documentation 
\begin_inset CommandInset citation
LatexCommand cite
key "DOC"

\end_inset

.
 
\end_layout

\begin_layout Standard
Given the distance robot to object and the horizontal distance from the
 robots center (x-value) we 
\end_layout

\begin_layout Section
Difficulties and future prospects
\end_layout

\begin_layout Subsection
Expressive Listening
\end_layout

\begin_layout Subsection
Blob detection
\end_layout

\begin_layout Standard
As a future improvement the minimal blob size should be adjusted dependending
 on the distance if the size of the searched object is given.
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Paragraph
Goals reached
\end_layout

\begin_layout Standard
The robot is able to listen to a color, detect this color and point towards
 it.
 
\end_layout

\begin_layout Paragraph
Limitations
\end_layout

\begin_layout Standard
So far only the colors which are specified in the code can be detected by
 the robot.
 This limits the interaction possiblities.
 A more interactive approach would be that any color could be said or that
 the words can be specified by the person interacting with the robot, e.g.
 via speech input.
 But permitting the robot to detect more colors is difficult, as colors
 appear quite different in changing light conditions.
 Distinguishing black, red, blue and green is easier as the RGB values are
 very different.
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
printbibliography
\end_layout

\end_inset


\end_layout

\end_body
\end_document
